{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b377e52c",
   "metadata": {},
   "source": [
    "# Tidying II: Deduplication, Type Consistency, & Categorical Integrity\n",
    "\n",
    "*Hands-on notebook with demos and exercises*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f939d39",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ecf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80c9097",
   "metadata": {},
   "source": [
    "## 1. Create Synthetic Datasets\n",
    "We will create small but realistic datasets with deliberate issues: duplicates, mixed types, messy categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87afbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customers: duplicates, whitespace, case inconsistencies, and missing values\n",
    "customers = pd.DataFrame({\n",
    "    'id': [101, 101, 102, 103, 103, 104, 105],\n",
    "    'email': ['a@x.com', 'A@x.com ', 'b@x.com', 'c@x.com', 'c@x.com', 'd@x.com', ' e@x.com'],\n",
    "    'state': ['tn', 'TN ', 'GA', 'ga', 'GA', 'AL', 'Tn'],\n",
    "    'created_at': ['2025-09-01', '2025/09/01', '2025-09-05', '2025-09-07', '2025-09-07', '2025-09-10', '2025-09-12']\n",
    "})\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions: partial duplicates by (id, ts), price as strings with symbols, and bad rows\n",
    "transactions = pd.DataFrame({\n",
    "    'id': [101, 101, 101, 102, 103, 103, 106],\n",
    "    'ts': ['2025-09-02 10:00', '2025-09-02 10:00', '2025-09-03 09:00', '2025-09-06 16:30', '2025-09-08 08:00', '2025-09-08 08:00', '2025-09-12 12:00'],\n",
    "    'price': ['$10.00', '10', '9.5', '7.25', '0', 'free', '12.5'],\n",
    "    'status': ['paid', 'paid', 'paid', 'paid', 'refunded', 'refunded', 'paid']\n",
    "})\n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba57b3",
   "metadata": {},
   "source": [
    "## 2. Deduplication: Detecting Exact vs Partial Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact duplicates across all columns in transactions\n",
    "transactions_exact_dups_mask = transactions.duplicated(keep=False)\n",
    "transactions[transactions_exact_dups_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64959e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial duplicates by a key subset: (id, ts)\n",
    "subset_cols = ['id', 'ts']\n",
    "dups_subset_mask = transactions.duplicated(subset=subset_cols, keep=False)\n",
    "transactions[dups_subset_mask].sort_values(subset_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14389b10",
   "metadata": {},
   "source": [
    "**Note:** `keep=False` marks all occurrences of a duplicate as `True`. Use it to inspect every row involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556be61a",
   "metadata": {},
   "source": [
    "## 3. Deduplication: Resolution Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Keep first occurrence by key\n",
    "tx_keep_first = transactions.drop_duplicates(subset=['id','ts'], keep='first')\n",
    "tx_keep_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3654736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Keep last occurrence by key\n",
    "tx_keep_last = transactions.drop_duplicates(subset=['id','ts'], keep='last')\n",
    "tx_keep_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950beeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Aggregate duplicates by key (sum price after converting to numeric; keep max timestamp string for demo)\n",
    "tx_tmp = transactions.copy()\n",
    "tx_tmp['price_num'] = pd.to_numeric(tx_tmp['price'].str.replace('$','', regex=False), errors='coerce')\n",
    "tx_agg = (\n",
    "    tx_tmp.groupby(['id','ts'], as_index=False)\n",
    "          .agg(price_total=('price_num','sum'), status_last=('status','last'))\n",
    ")\n",
    "tx_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373f9c7",
   "metadata": {},
   "source": [
    "**Guideline:** Document which rule is applied and why. Aggregation is appropriate when each row is a component of a single logical event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7ed19",
   "metadata": {},
   "source": [
    "## 4. Practical Deduplication Recipe with Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by time and keep latest per (id, ts)\n",
    "tx_sorted = transactions.sort_values('ts')\n",
    "tx_unique = tx_sorted.drop_duplicates(subset=['id','ts'], keep='last')\n",
    "\n",
    "# Verify no duplicates remain on the key\n",
    "assert not tx_unique.duplicated(subset=['id','ts']).any()\n",
    "tx_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d856ee",
   "metadata": {},
   "source": [
    "## 5. Type Conversion: Inspecting and Enforcing Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12880c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect\n",
    "customers.info()\n",
    "transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "customers['created_at'] = pd.to_datetime(customers['created_at'], errors='coerce')\n",
    "transactions['ts'] = pd.to_datetime(transactions['ts'], errors='coerce')\n",
    "\n",
    "customers.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert price to numeric\n",
    "transactions['price_num'] = pd.to_numeric(transactions['price'].str.replace('$','', regex=False), errors='coerce')\n",
    "\n",
    "transactions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74257b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatives to 'coerce' for error handling\n",
    "try:\n",
    "    pd.to_numeric(pd.Series(['1','two','3']), errors='raise')\n",
    "except Exception as e:\n",
    "    print(\"errors='raise' example ->\", repr(e))\n",
    "\n",
    "# errors='ignore' leaves data unchanged if invalid\n",
    "print(pd.to_numeric(pd.Series(['1','two','3']), errors='ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823bad49",
   "metadata": {},
   "source": [
    "## 6. `convert_dtypes()` and Explicit `astype()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e341995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_dtypes picks best nullable dtypes\n",
    "auto_customers = customers.convert_dtypes()\n",
    "\n",
    "auto_customers.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968529f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_transactions = transactions.convert_dtypes()\n",
    "auto_transactions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit casting of multiple columns\n",
    "casted = transactions.astype({'price_num': 'float64'})\n",
    "casted.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e51f25",
   "metadata": {},
   "source": [
    "## 7. Validating Type Integrity and Logical Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.api.types as ptypes\n",
    "assert ptypes.is_datetime64_any_dtype(customers['created_at'])\n",
    "assert ptypes.is_datetime64_any_dtype(transactions['ts'])\n",
    "assert ptypes.is_numeric_dtype(transactions['price_num'])\n",
    "\n",
    "# Logical constraints\n",
    "assert (transactions['price_num'].fillna(0) >= 0).all()  # Nonnegative\n",
    "print(\"Type and logical checks passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778d07b",
   "metadata": {},
   "source": [
    "## 8. Categorical Data: Normalization, Enforcement, and Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize state values\n",
    "customers['state_norm'] = customers['state'].str.upper().str.strip()\n",
    "\n",
    "# Enforce allowed categories\n",
    "state_type = CategoricalDtype(categories=['TN','GA','AL'], ordered=False)\n",
    "customers['state_cat'] = customers['state_norm'].astype(state_type)\n",
    "\n",
    "# Detect drift\n",
    "invalid_mask = ~customers['state'].isin(state_type.categories)\n",
    "customers[['id','state','state_norm','state_cat']][invalid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect drift\n",
    "invalid_mask = ~customers['state_norm'].isin(state_type.categories)\n",
    "customers[['id','state','state_norm','state_cat']][invalid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68edafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map gender example and enforce categories\n",
    "demo = pd.DataFrame({'gender': ['Male','male','M','Female','F','unknown', np.nan]})\n",
    "demo['gender_std'] = demo['gender'].replace({'male':'Male','M':'Male','female':'Female','F':'Female'})\n",
    "\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = ['Male','Female']\n",
    "invalid = ~demo['gender_std'].isin(allowed)\n",
    "\n",
    "demo[invalid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86649e3",
   "metadata": {},
   "source": [
    "## 9. Clean Joins After Dedup and Type Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8a0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare customers: deduplicate by (id, email after trim+lower)\n",
    "cust_norm = customers.assign(\n",
    "    email_norm = customers['email'].str.strip().str.lower()\n",
    ").sort_values('created_at')\n",
    "\n",
    "cust_unique = cust_norm.drop_duplicates(subset=['id','email_norm'], keep='last')\n",
    "\n",
    "# Verify uniqueness\n",
    "assert not cust_unique.duplicated(subset=['id']).any()\n",
    "\n",
    "# Safe join with transactions\n",
    "tx_clean = transactions[['id','ts','price_num','status']].drop_duplicates(subset=['id','ts'], keep='last')\n",
    "fact = tx_clean.merge(cust_unique[['id','email_norm','state_cat']], on='id', how='left')\n",
    "fact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42f56a",
   "metadata": {},
   "source": [
    "## 10. Documenting Cleaning Decisions\n",
    "| Step | Action                 | Columns                    | Notes                                  |\n",
    "|-----:|------------------------|----------------------------|----------------------------------------|\n",
    "| 1    | Drop duplicates        | id, ts                     | Keep last per (id, ts)                 |\n",
    "| 2    | Convert numeric/date   | price → price_num, ts      | `errors='coerce'` for robustness       |\n",
    "| 3    | Normalize categories   | state → state_norm/state_cat | Uppercase + strict category set      |\n",
    "| 4    | Validate constraints   | price_num, ts              | Nonnegative prices, valid datetimes    |\n",
    "| 5    | Reproducible joins     | id                         | Verified unique keys                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5122fb3e",
   "metadata": {},
   "source": [
    "## 11. Exercises\n",
    "Complete the tasks below. Answers are provided in the subsequent section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae89d8",
   "metadata": {},
   "source": [
    "**Exercise 1.** Identify all partial duplicates in `transactions` by keys `(id, ts)` and return a deduplicated frame keeping the **highest** `price_num` per key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here\n",
    "# 1) Mark duplicates by subset\n",
    "# 2) Aggregate by max(price_num)\n",
    "# 3) Merge back or compute directly\n",
    "# expected columns: id, ts, price_num_max\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065e636",
   "metadata": {},
   "source": [
    "**Exercise 2.** Convert `customers['created_at']` to datetime with `errors='raise'`. Catch and display the error, then convert correctly with a strict `format` specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here\n",
    "# 1) Try strict conversion and handle exception\n",
    "# 2) Then convert again using format='%Y-%m-%d' for the rows that match, coerce others\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85849142",
   "metadata": {},
   "source": [
    "**Exercise 3.** Enforce a categorical dtype for `customers['state_norm']` limited to `['TN','GA','AL']`. Show rows that become NaN after enforcement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here\n",
    "# 1) Define CategoricalDtype\n",
    "# 2) astype to that type\n",
    "# 3) filter rows where value is NaN in enforced column\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804cfe7",
   "metadata": {},
   "source": [
    "**Exercise 4.** Prove that `cust_unique['id']` is unique using two independent checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here\n",
    "# e.g., use .is_unique and duplicated().any()\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
